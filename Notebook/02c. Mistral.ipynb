{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-21T03:51:05.758021Z",
     "start_time": "2025-04-21T03:51:05.062080Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown\n",
    "from mistralai import Mistral\n",
    "from mistralai import DocumentURLChunk, ImageURLChunk, TextChunk\n",
    "import json\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize Clients",
   "id": "c96dab1e66931f7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:51:05.793875Z",
     "start_time": "2025-04-21T03:51:05.761384Z"
    }
   },
   "cell_type": "code",
   "source": "client = Mistral(api_key=os.getenv(\"MISTRAL_API_KEY\"))",
   "id": "7d27fec5fa2ece8a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Batch File",
   "id": "e68a27b825203236"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:51:05.848295Z",
     "start_time": "2025-04-21T03:51:05.803008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folder_path = \"../Data/Raw\"\n",
    "text_list = []\n",
    "\n",
    "# Iterate over each file in the folder with a progress bar.\n",
    "for filename in tqdm.tqdm(os.listdir(folder_path), desc=\"Processing files\"):\n",
    "    file_title = os.path.basename(filename)\n",
    "    # Process only files that end with '.txt'\n",
    "    if filename.lower().endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Open and read the file content.\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        text_list.append(text)"
   ],
   "id": "39a861190f27eb5d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 11/11 [00:00<00:00, 506.99it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cognee",
   "id": "f3c3cec4b791492b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:51:05.857134Z",
     "start_time": "2025-04-21T03:51:05.854052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setting environment variables\n",
    "if \"GRAPHISTRY_USERNAME\" not in os.environ:\n",
    "    os.environ[\"GRAPHISTRY_USERNAME\"] = \"reveriano893\"\n",
    "\n",
    "if \"GRAPHISTRY_PASSWORD\" not in os.environ:\n",
    "    os.environ[\"GRAPHISTRY_PASSWORD\"] = \"Gloria77!Gloria77!\"\n",
    "\n",
    "if \"LLM_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LLM_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# \"neo4j\" or \"networkx\"\n",
    "os.environ[\"GRAPH_DATABASE_PROVIDER\"]=\"networkx\"\n",
    "# Not needed if using networkx\n",
    "#os.environ[\"GRAPH_DATABASE_URL\"]=\"\"\n",
    "#os.environ[\"GRAPH_DATABASE_USERNAME\"]=\"\"\n",
    "#os.environ[\"GRAPH_DATABASE_PASSWORD\"]=\"\"\n",
    "\n",
    "# \"pgvector\", \"qdrant\", \"weaviate\" or \"lancedb\"\n",
    "os.environ[\"VECTOR_DB_PROVIDER\"]=\"lancedb\"\n",
    "# Not needed if using \"lancedb\" or \"pgvector\"\n",
    "# os.environ[\"VECTOR_DB_URL\"]=\"\"\n",
    "# os.environ[\"VECTOR_DB_KEY\"]=\"\"\n",
    "\n",
    "# Relational Database provider \"sqlite\" or \"postgres\"\n",
    "os.environ[\"DB_PROVIDER\"]=\"sqlite\"\n",
    "\n",
    "# Database name\n",
    "os.environ[\"DB_NAME\"]=\"cognee_db\""
   ],
   "id": "3212d637d7331780",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:51:11.840641Z",
     "start_time": "2025-04-21T03:51:05.862337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Union, BinaryIO\n",
    "\n",
    "from cognee.infrastructure.databases.vector.pgvector import create_db_and_tables as create_pgvector_db_and_tables\n",
    "from cognee.infrastructure.databases.relational import create_db_and_tables as create_relational_db_and_tables\n",
    "from cognee.modules.users.models import User\n",
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.tasks.ingestion.ingest_data import ingest_data\n",
    "import cognee\n",
    "\n",
    "# Create a clean slate for cognee -- reset data and system state\n",
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "\n",
    "# Add the LlamaIndex documents, and make it available for cognify\n",
    "async def add(data: Union[BinaryIO, list[BinaryIO], str, list[str]], dataset_name: str = \"main_dataset\", user: User = None):\n",
    "    await create_relational_db_and_tables()\n",
    "    await create_pgvector_db_and_tables()\n",
    "\n",
    "    if user is None:\n",
    "        user = await get_default_user()\n",
    "\n",
    "    await ingest_data(data, dataset_name, user)\n",
    "\n",
    "await cognee.add(text_list)"
   ],
   "id": "71c1cdc01e3b4192",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File /Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/.cognee_system/databases/cognee_graph.pkl not found. Initializing an empty graph."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database deleted successfully.\n",
      "User 2efd80e7-88b9-4734-82cc-b52b35ad2b59 has registered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/merge_job.py:194: SAWarning: Table 'file_metadata' already exists within the given MetaData - not copying.\n",
      "  staging_table_obj = table_obj.to_metadata(\n",
      "/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/merge_job.py:229: SAWarning: implicitly coercing SELECT object to scalar subquery; please use the .scalar_subquery() method to produce a scalar subquery.\n",
      "  order_by=order_dir_func(order_by_col),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline file_load_from_filesystem load step completed in 0.06 seconds\n",
      "1 load package(s) were loaded to destination sqlalchemy and into dataset main\n",
      "The sqlalchemy destination used sqlite:////Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/.cognee_system/databases/cognee_db location to store data\n",
      "Load package 1745207470.9747431 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:51:16.723874Z",
     "start_time": "2025-04-21T03:51:11.970645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use LLMs and cognee to create knowledge graph\n",
    "await cognee.cognify()"
   ],
   "id": "c0f190fdc0f2ccee",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed after retries: <bound method Future.exception of <Future at 0x319461b50 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319461b50 state=finished raised APIError>]Failed after retries: <bound method Future.exception of <Future at 0x319461fd0 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319461fd0 state=finished raised APIError>]Failed after retries: <bound method Future.exception of <Future at 0x319478730 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319478730 state=finished raised APIError>]Failed after retries: <bound method Future.exception of <Future at 0x319478d00 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319478d00 state=finished raised APIError>]Failed after retries: <bound method Future.exception of <Future at 0x319478bb0 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319478bb0 state=finished raised APIError>]Failed after retries: <bound method Future.exception of <Future at 0x319478b80 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319478b80 state=finished raised APIError>]Failed after retries: <bound method Future.exception of <Future at 0x31949ae80 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x31949ae80 state=finished raised APIError>]Failed after retries: <bound method Future.exception of <Future at 0x3194a24c0 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x3194a24c0 state=finished raised APIError>]Failed after retries: <bound method Future.exception of <Future at 0x3194a2a90 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x3194a2a90 state=finished raised APIError>]Failed after retries: <bound method Future.exception of <Future at 0x319461400 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319461400 state=finished raised APIError>]Coroutine task errored: `extract_graph_from_data`\n",
      "litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319461b50 state=finished raised APIError>]\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 116, in run_tasks_base\n",
      "    task_result = await running_task.run(*args)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/tasks/graph/extract_graph_from_data.py\", line 19, in extract_graph_from_data\n",
      "    chunk_graphs = await asyncio.gather(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/data/extraction/knowledge_graph/extract_content_graph.py\", line 10, in extract_content_graph\n",
      "    content_graph = await llm_client.acreate_structured_output(content, system_prompt, response_model)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/infrastructure/llm/openai/adapter.py\", line 42, in acreate_structured_output\n",
      "    return await self.aclient.chat.completions.create(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/client.py\", line 311, in create\n",
      "    return await self.create_fn(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/patch.py\", line 255, in new_create_async\n",
      "    response = await retry_async(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 306, in retry_async\n",
      "    raise InstructorRetryException(\n",
      "instructor.exceptions.InstructorRetryException: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Async generator task errored: `extract_chunks_from_documents`\n",
      "litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319461b50 state=finished raised APIError>]\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 40, in run_tasks_base\n",
      "    async for result in run_tasks_base(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 135, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 116, in run_tasks_base\n",
      "    task_result = await running_task.run(*args)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/tasks/graph/extract_graph_from_data.py\", line 19, in extract_graph_from_data\n",
      "    chunk_graphs = await asyncio.gather(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/data/extraction/knowledge_graph/extract_content_graph.py\", line 10, in extract_content_graph\n",
      "    content_graph = await llm_client.acreate_structured_output(content, system_prompt, response_model)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/infrastructure/llm/openai/adapter.py\", line 42, in acreate_structured_output\n",
      "    return await self.aclient.chat.completions.create(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/client.py\", line 311, in create\n",
      "    return await self.create_fn(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/patch.py\", line 255, in new_create_async\n",
      "    response = await retry_async(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 306, in retry_async\n",
      "    raise InstructorRetryException(\n",
      "instructor.exceptions.InstructorRetryException: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'Coroutine task errored: `check_permissions_on_documents`\n",
      "litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319461b50 state=finished raised APIError>]\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 118, in run_tasks_base\n",
      "    async for result in run_tasks_base(leftover_tasks, task_result, user):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 69, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 40, in run_tasks_base\n",
      "    async for result in run_tasks_base(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 135, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 116, in run_tasks_base\n",
      "    task_result = await running_task.run(*args)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/tasks/graph/extract_graph_from_data.py\", line 19, in extract_graph_from_data\n",
      "    chunk_graphs = await asyncio.gather(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/data/extraction/knowledge_graph/extract_content_graph.py\", line 10, in extract_content_graph\n",
      "    content_graph = await llm_client.acreate_structured_output(content, system_prompt, response_model)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/infrastructure/llm/openai/adapter.py\", line 42, in acreate_structured_output\n",
      "    return await self.aclient.chat.completions.create(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/client.py\", line 311, in create\n",
      "    return await self.create_fn(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/patch.py\", line 255, in new_create_async\n",
      "    response = await retry_async(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 306, in retry_async\n",
      "    raise InstructorRetryException(\n",
      "instructor.exceptions.InstructorRetryException: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'Coroutine task errored: `classify_documents`\n",
      "litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319461b50 state=finished raised APIError>]\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 118, in run_tasks_base\n",
      "    async for result in run_tasks_base(leftover_tasks, task_result, user):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 135, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 118, in run_tasks_base\n",
      "    async for result in run_tasks_base(leftover_tasks, task_result, user):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 69, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 40, in run_tasks_base\n",
      "    async for result in run_tasks_base(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 135, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 116, in run_tasks_base\n",
      "    task_result = await running_task.run(*args)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/tasks/graph/extract_graph_from_data.py\", line 19, in extract_graph_from_data\n",
      "    chunk_graphs = await asyncio.gather(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/data/extraction/knowledge_graph/extract_content_graph.py\", line 10, in extract_content_graph\n",
      "    content_graph = await llm_client.acreate_structured_output(content, system_prompt, response_model)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/infrastructure/llm/openai/adapter.py\", line 42, in acreate_structured_output\n",
      "    return await self.aclient.chat.completions.create(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/client.py\", line 311, in create\n",
      "    return await self.create_fn(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/patch.py\", line 255, in new_create_async\n",
      "    response = await retry_async(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 306, in retry_async\n",
      "    raise InstructorRetryException(\n",
      "instructor.exceptions.InstructorRetryException: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'Pipeline run errored: `cognify_pipeline`\n",
      "litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 843, in acompletion\n",
      "    openai_aclient: AsyncOpenAI = self._get_openai_client(  # type: ignore\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 530, in _get_openai_client\n",
      "    _new_client: Union[OpenAI, AsyncOpenAI] = AsyncOpenAI(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py\", line 337, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1437, in __init__\n",
      "    self._client = http_client or AsyncHttpxClientWrapper(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py\", line 1334, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 441, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py\", line 898, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.OpenAIError: __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 271, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1585, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py\", line 1398, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py\", line 463, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2131, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 419, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 267, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x319461b50 state=finished raised APIError>]\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 179, in run_tasks_with_telemetry\n",
      "    async for result in run_tasks_base(tasks, data, user):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 135, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 118, in run_tasks_base\n",
      "    async for result in run_tasks_base(leftover_tasks, task_result, user):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 135, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 118, in run_tasks_base\n",
      "    async for result in run_tasks_base(leftover_tasks, task_result, user):\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 69, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 40, in run_tasks_base\n",
      "    async for result in run_tasks_base(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 135, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py\", line 116, in run_tasks_base\n",
      "    task_result = await running_task.run(*args)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/tasks/graph/extract_graph_from_data.py\", line 19, in extract_graph_from_data\n",
      "    chunk_graphs = await asyncio.gather(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/data/extraction/knowledge_graph/extract_content_graph.py\", line 10, in extract_content_graph\n",
      "    content_graph = await llm_client.acreate_structured_output(content, system_prompt, response_model)\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/infrastructure/llm/openai/adapter.py\", line 42, in acreate_structured_output\n",
      "    return await self.aclient.chat.completions.create(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/client.py\", line 311, in create\n",
      "    return await self.create_fn(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/patch.py\", line 255, in new_create_async\n",
      "    response = await retry_async(\n",
      "  File \"/Users/Francisco_Reveriano/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py\", line 306, in retry_async\n",
      "    raise InstructorRetryException(\n",
      "instructor.exceptions.InstructorRetryException: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'"
     ]
    },
    {
     "ename": "InstructorRetryException",
     "evalue": "litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py:843\u001B[0m, in \u001B[0;36mOpenAIChatCompletion.acompletion\u001B[0;34m(self, data, model_response, logging_obj, timeout, api_key, api_base, organization, client, max_retries, headers, drop_params)\u001B[0m\n\u001B[1;32m    842\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 843\u001B[0m     openai_aclient: AsyncOpenAI \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_openai_client\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m    844\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_async\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_base\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_base\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m        \u001B[49m\u001B[43morganization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morganization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;66;03m## LOGGING\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py:530\u001B[0m, in \u001B[0;36mOpenAIChatCompletion._get_openai_client\u001B[0;34m(self, is_async, api_key, api_base, timeout, max_retries, organization, client)\u001B[0m\n\u001B[1;32m    529\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_async:\n\u001B[0;32m--> 530\u001B[0m     _new_client: Union[OpenAI, AsyncOpenAI] \u001B[38;5;241m=\u001B[39m \u001B[43mAsyncOpenAI\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    532\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbase_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_base\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    533\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhttp_client\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlitellm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maclient_session\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    534\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    535\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[43m        \u001B[49m\u001B[43morganization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morganization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    537\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_client.py:337\u001B[0m, in \u001B[0;36mAsyncOpenAI.__init__\u001B[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001B[0m\n\u001B[1;32m    335\u001B[0m     base_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://api.openai.com/v1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 337\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m    \u001B[49m\u001B[43mversion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m__version__\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhttp_client\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhttp_client\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_strict_response_validation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_strict_response_validation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_default_stream_cls \u001B[38;5;241m=\u001B[39m AsyncStream\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py:1437\u001B[0m, in \u001B[0;36mAsyncAPIClient.__init__\u001B[0;34m(self, version, base_url, _strict_response_validation, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query)\u001B[0m\n\u001B[1;32m   1424\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m   1425\u001B[0m     version\u001B[38;5;241m=\u001B[39mversion,\n\u001B[1;32m   1426\u001B[0m     base_url\u001B[38;5;241m=\u001B[39mbase_url,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1435\u001B[0m     _strict_response_validation\u001B[38;5;241m=\u001B[39m_strict_response_validation,\n\u001B[1;32m   1436\u001B[0m )\n\u001B[0;32m-> 1437\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client \u001B[38;5;241m=\u001B[39m http_client \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mAsyncHttpxClientWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1438\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1439\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001B[39;49;00m\n\u001B[1;32m   1440\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1441\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1442\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransport\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransport\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1443\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlimits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimits\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1444\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1445\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/openai/_base_client.py:1334\u001B[0m, in \u001B[0;36m_DefaultAsyncHttpxClient.__init__\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m   1333\u001B[0m kwargs\u001B[38;5;241m.\u001B[39msetdefault(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfollow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m-> 1334\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'proxies'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mOpenAIError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py:441\u001B[0m, in \u001B[0;36macompletion\u001B[0;34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, base_url, api_version, api_key, model_list, extra_headers, **kwargs)\u001B[0m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39miscoroutine(init_response):\n\u001B[0;32m--> 441\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m init_response\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/llms/OpenAI/openai.py:898\u001B[0m, in \u001B[0;36mOpenAIChatCompletion.acompletion\u001B[0;34m(self, data, model_response, logging_obj, timeout, api_key, api_base, organization, client, max_retries, headers, drop_params)\u001B[0m\n\u001B[1;32m    896\u001B[0m     error_headers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(exception_response, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 898\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m OpenAIError(\n\u001B[1;32m    899\u001B[0m     status_code\u001B[38;5;241m=\u001B[39mstatus_code, message\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e), headers\u001B[38;5;241m=\u001B[39merror_headers\n\u001B[1;32m    900\u001B[0m )\n",
      "\u001B[0;31mOpenAIError\u001B[0m: __init__() got an unexpected keyword argument 'proxies'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAPIError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py:271\u001B[0m, in \u001B[0;36mretry_async\u001B[0;34m(func, response_model, context, args, kwargs, max_retries, strict, mode)\u001B[0m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 271\u001B[0m     response: ChatCompletion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    272\u001B[0m     stream \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py:1585\u001B[0m, in \u001B[0;36mclient.<locals>.wrapper_async\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1584\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m original_function(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 1585\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/utils.py:1398\u001B[0m, in \u001B[0;36mclient.<locals>.wrapper_async\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1397\u001B[0m \u001B[38;5;66;03m# MODEL CALL\u001B[39;00m\n\u001B[0;32m-> 1398\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m original_function(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1399\u001B[0m end_time \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mdatetime\u001B[38;5;241m.\u001B[39mnow()\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/main.py:463\u001B[0m, in \u001B[0;36macompletion\u001B[0;34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, base_url, api_version, api_key, model_list, extra_headers, **kwargs)\u001B[0m\n\u001B[1;32m    462\u001B[0m custom_llm_provider \u001B[38;5;241m=\u001B[39m custom_llm_provider \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 463\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[43mexception_type\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    464\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    465\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_llm_provider\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_llm_provider\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    466\u001B[0m \u001B[43m    \u001B[49m\u001B[43moriginal_exception\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompletion_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompletion_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextra_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    469\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2131\u001B[0m, in \u001B[0;36mexception_type\u001B[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001B[0m\n\u001B[1;32m   2130\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlitellm_response_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m, litellm_response_headers)\n\u001B[0;32m-> 2131\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m   2132\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:419\u001B[0m, in \u001B[0;36mexception_type\u001B[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001B[0m\n\u001B[1;32m    418\u001B[0m         exception_mapping_worked \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 419\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m APIError(\n\u001B[1;32m    420\u001B[0m             status_code\u001B[38;5;241m=\u001B[39moriginal_exception\u001B[38;5;241m.\u001B[39mstatus_code,\n\u001B[1;32m    421\u001B[0m             message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPIError: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexception_provider\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmessage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    422\u001B[0m             llm_provider\u001B[38;5;241m=\u001B[39mcustom_llm_provider,\n\u001B[1;32m    423\u001B[0m             model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m    424\u001B[0m             request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(original_exception, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequest\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    425\u001B[0m             litellm_debug_info\u001B[38;5;241m=\u001B[39mextra_information,\n\u001B[1;32m    426\u001B[0m         )\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;66;03m# if no status code then it is an APIConnectionError: https://github.com/openai/openai-python#handling-errors\u001B[39;00m\n\u001B[1;32m    429\u001B[0m     \u001B[38;5;66;03m# exception_mapping_worked = True\u001B[39;00m\n",
      "\u001B[0;31mAPIError\u001B[0m: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRetryError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py:267\u001B[0m, in \u001B[0;36mretry_async\u001B[0;34m(func, response_model, context, args, kwargs, max_retries, strict, mode)\u001B[0m\n\u001B[1;32m    266\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m attempt \u001B[38;5;129;01min\u001B[39;00m max_retries:\n\u001B[1;32m    268\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRetrying, attempt: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattempt\u001B[38;5;241m.\u001B[39mretry_state\u001B[38;5;241m.\u001B[39mattempt_number\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py:166\u001B[0m, in \u001B[0;36mAsyncRetrying.__anext__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 166\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter(retry_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retry_state)\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m do \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/asyncio/__init__.py:153\u001B[0m, in \u001B[0;36mAsyncRetrying.iter\u001B[0;34m(self, retry_state)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m action \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_state\u001B[38;5;241m.\u001B[39mactions:\n\u001B[0;32m--> 153\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m action(retry_state)\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/_utils.py:99\u001B[0m, in \u001B[0;36mwrap_to_async_func.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs: typing\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: typing\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m typing\u001B[38;5;241m.\u001B[39mAny:\n\u001B[0;32m---> 99\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/tenacity/__init__.py:419\u001B[0m, in \u001B[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001B[0;34m(rs)\u001B[0m\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m retry_exc\u001B[38;5;241m.\u001B[39mreraise()\n\u001B[0;32m--> 419\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m retry_exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfut\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexception\u001B[39;00m()\n",
      "\u001B[0;31mRetryError\u001B[0m: RetryError[<Future at 0x319461b50 state=finished raised APIError>]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mInstructorRetryException\u001B[0m                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Use LLMs and cognee to create knowledge graph\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m cognee\u001B[38;5;241m.\u001B[39mcognify()\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/api/v1/cognify/cognify_v2.py:53\u001B[0m, in \u001B[0;36mcognify\u001B[0;34m(datasets, user)\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dataset_name \u001B[38;5;129;01min\u001B[39;00m existing_datasets_map:\n\u001B[1;32m     51\u001B[0m         awaitables\u001B[38;5;241m.\u001B[39mappend(run_cognify_pipeline(dataset, user))\n\u001B[0;32m---> 53\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39mgather(\u001B[38;5;241m*\u001B[39mawaitables)\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/api/v1/cognify/cognify_v2.py:113\u001B[0m, in \u001B[0;36mrun_cognify_pipeline\u001B[0;34m(dataset, user)\u001B[0m\n\u001B[1;32m    107\u001B[0m send_telemetry(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcognee.cognify EXECUTION ERRORED\u001B[39m\u001B[38;5;124m\"\u001B[39m, user\u001B[38;5;241m.\u001B[39mid)\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m log_pipeline_status(dataset_id, PipelineRunStatus\u001B[38;5;241m.\u001B[39mDATASET_PROCESSING_ERRORED, {\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: dataset_name,\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfiles\u001B[39m\u001B[38;5;124m\"\u001B[39m: document_ids_str,\n\u001B[1;32m    112\u001B[0m })\n\u001B[0;32m--> 113\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m error\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/api/v1/cognify/cognify_v2.py:95\u001B[0m, in \u001B[0;36mrun_cognify_pipeline\u001B[0;34m(dataset, user)\u001B[0m\n\u001B[1;32m     80\u001B[0m tasks \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     81\u001B[0m     Task(classify_documents),\n\u001B[1;32m     82\u001B[0m     Task(check_permissions_on_documents, user \u001B[38;5;241m=\u001B[39m user, permissions \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwrite\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     90\u001B[0m     Task(add_data_points, task_config \u001B[38;5;241m=\u001B[39m { \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m10\u001B[39m }),\n\u001B[1;32m     91\u001B[0m ]\n\u001B[1;32m     93\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m run_tasks(tasks, data_documents, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcognify_pipeline\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 95\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m pipeline:\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28mprint\u001B[39m(result)\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m index_graph_edges()\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:203\u001B[0m, in \u001B[0;36mrun_tasks\u001B[0;34m(tasks, data, pipeline_name)\u001B[0m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrun_tasks\u001B[39m(tasks: \u001B[38;5;28mlist\u001B[39m[Task], data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, pipeline_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault_pipeline\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 203\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m run_tasks_with_telemetry(tasks, data, pipeline_name):\n\u001B[1;32m    204\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m result\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:199\u001B[0m, in \u001B[0;36mrun_tasks_with_telemetry\u001B[0;34m(tasks, data, pipeline_name)\u001B[0m\n\u001B[1;32m    188\u001B[0m logger\u001B[38;5;241m.\u001B[39merror(\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline run errored: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    190\u001B[0m     pipeline_name,\n\u001B[1;32m    191\u001B[0m     \u001B[38;5;28mstr\u001B[39m(error),\n\u001B[1;32m    192\u001B[0m     exc_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    193\u001B[0m )\n\u001B[1;32m    194\u001B[0m send_telemetry(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline Run Errored\u001B[39m\u001B[38;5;124m\"\u001B[39m, \n\u001B[1;32m    195\u001B[0m                user\u001B[38;5;241m.\u001B[39mid, \n\u001B[1;32m    196\u001B[0m                additional_properties \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpipeline_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: pipeline_name, } \u001B[38;5;241m|\u001B[39m config\n\u001B[1;32m    197\u001B[0m                )\n\u001B[0;32m--> 199\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m error\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:179\u001B[0m, in \u001B[0;36mrun_tasks_with_telemetry\u001B[0;34m(tasks, data, pipeline_name)\u001B[0m\n\u001B[1;32m    173\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline run started: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m, pipeline_name)\n\u001B[1;32m    174\u001B[0m send_telemetry(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline Run Started\u001B[39m\u001B[38;5;124m\"\u001B[39m, \n\u001B[1;32m    175\u001B[0m                user\u001B[38;5;241m.\u001B[39mid, \n\u001B[1;32m    176\u001B[0m                additional_properties \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpipeline_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: pipeline_name, } \u001B[38;5;241m|\u001B[39m config\n\u001B[1;32m    177\u001B[0m                )\n\u001B[0;32m--> 179\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m run_tasks_base(tasks, data, user):\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m result\n\u001B[1;32m    182\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline run completed: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m, pipeline_name)\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:135\u001B[0m, in \u001B[0;36mrun_tasks_base\u001B[0;34m(tasks, data, user)\u001B[0m\n\u001B[1;32m    126\u001B[0m         logger\u001B[38;5;241m.\u001B[39merror(\n\u001B[1;32m    127\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCoroutine task errored: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    128\u001B[0m             running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m    129\u001B[0m             \u001B[38;5;28mstr\u001B[39m(error),\n\u001B[1;32m    130\u001B[0m             exc_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    131\u001B[0m         )\n\u001B[1;32m    132\u001B[0m         send_telemetry(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCoroutine Task Errored\u001B[39m\u001B[38;5;124m\"\u001B[39m, user\u001B[38;5;241m.\u001B[39mid, {\n\u001B[1;32m    133\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m    134\u001B[0m         })\n\u001B[0;32m--> 135\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m error\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misfunction(running_task\u001B[38;5;241m.\u001B[39mexecutable):\n\u001B[1;32m    138\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFunction task started: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m, running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:118\u001B[0m, in \u001B[0;36mrun_tasks_base\u001B[0;34m(tasks, data, user)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    116\u001B[0m     task_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m running_task\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m--> 118\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m run_tasks_base(leftover_tasks, task_result, user):\n\u001B[1;32m    119\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m result\n\u001B[1;32m    121\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCoroutine task completed: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m, running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:135\u001B[0m, in \u001B[0;36mrun_tasks_base\u001B[0;34m(tasks, data, user)\u001B[0m\n\u001B[1;32m    126\u001B[0m         logger\u001B[38;5;241m.\u001B[39merror(\n\u001B[1;32m    127\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCoroutine task errored: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    128\u001B[0m             running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m    129\u001B[0m             \u001B[38;5;28mstr\u001B[39m(error),\n\u001B[1;32m    130\u001B[0m             exc_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    131\u001B[0m         )\n\u001B[1;32m    132\u001B[0m         send_telemetry(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCoroutine Task Errored\u001B[39m\u001B[38;5;124m\"\u001B[39m, user\u001B[38;5;241m.\u001B[39mid, {\n\u001B[1;32m    133\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m    134\u001B[0m         })\n\u001B[0;32m--> 135\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m error\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misfunction(running_task\u001B[38;5;241m.\u001B[39mexecutable):\n\u001B[1;32m    138\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFunction task started: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m, running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:118\u001B[0m, in \u001B[0;36mrun_tasks_base\u001B[0;34m(tasks, data, user)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    116\u001B[0m     task_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m running_task\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m--> 118\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m run_tasks_base(leftover_tasks, task_result, user):\n\u001B[1;32m    119\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m result\n\u001B[1;32m    121\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCoroutine task completed: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m, running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:69\u001B[0m, in \u001B[0;36mrun_tasks_base\u001B[0;34m(tasks, data, user)\u001B[0m\n\u001B[1;32m     60\u001B[0m         logger\u001B[38;5;241m.\u001B[39merror(\n\u001B[1;32m     61\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsync generator task errored: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     62\u001B[0m             running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m     63\u001B[0m             \u001B[38;5;28mstr\u001B[39m(error),\n\u001B[1;32m     64\u001B[0m             exc_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     65\u001B[0m         )\n\u001B[1;32m     66\u001B[0m         send_telemetry(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsync Generator Task Errored\u001B[39m\u001B[38;5;124m\"\u001B[39m, user\u001B[38;5;241m.\u001B[39mid, {\n\u001B[1;32m     67\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m     68\u001B[0m         })\n\u001B[0;32m---> 69\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m error\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misgeneratorfunction(running_task\u001B[38;5;241m.\u001B[39mexecutable):\n\u001B[1;32m     72\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerator task started: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m, running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:40\u001B[0m, in \u001B[0;36mrun_tasks_base\u001B[0;34m(tasks, data, user)\u001B[0m\n\u001B[1;32m     37\u001B[0m results\u001B[38;5;241m.\u001B[39mappend(partial_result)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(results) \u001B[38;5;241m==\u001B[39m next_task_batch_size:\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m run_tasks_base(\n\u001B[1;32m     41\u001B[0m         leftover_tasks,\n\u001B[1;32m     42\u001B[0m         results[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m next_task_batch_size \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m results,\n\u001B[1;32m     43\u001B[0m         user \u001B[38;5;241m=\u001B[39m user,\n\u001B[1;32m     44\u001B[0m     ):\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m result\n\u001B[1;32m     47\u001B[0m     results \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:135\u001B[0m, in \u001B[0;36mrun_tasks_base\u001B[0;34m(tasks, data, user)\u001B[0m\n\u001B[1;32m    126\u001B[0m         logger\u001B[38;5;241m.\u001B[39merror(\n\u001B[1;32m    127\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCoroutine task errored: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    128\u001B[0m             running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m    129\u001B[0m             \u001B[38;5;28mstr\u001B[39m(error),\n\u001B[1;32m    130\u001B[0m             exc_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    131\u001B[0m         )\n\u001B[1;32m    132\u001B[0m         send_telemetry(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCoroutine Task Errored\u001B[39m\u001B[38;5;124m\"\u001B[39m, user\u001B[38;5;241m.\u001B[39mid, {\n\u001B[1;32m    133\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m    134\u001B[0m         })\n\u001B[0;32m--> 135\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m error\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misfunction(running_task\u001B[38;5;241m.\u001B[39mexecutable):\n\u001B[1;32m    138\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFunction task started: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m, running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/pipelines/operations/run_tasks.py:116\u001B[0m, in \u001B[0;36mrun_tasks_base\u001B[0;34m(tasks, data, user)\u001B[0m\n\u001B[1;32m    112\u001B[0m send_telemetry(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCoroutine Task Started\u001B[39m\u001B[38;5;124m\"\u001B[39m, user_id \u001B[38;5;241m=\u001B[39m user\u001B[38;5;241m.\u001B[39mid, additional_properties \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    113\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: running_task\u001B[38;5;241m.\u001B[39mexecutable\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m    114\u001B[0m })\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 116\u001B[0m     task_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m running_task\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m run_tasks_base(leftover_tasks, task_result, user):\n\u001B[1;32m    119\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m result\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/tasks/graph/extract_graph_from_data.py:19\u001B[0m, in \u001B[0;36mextract_graph_from_data\u001B[0;34m(data_chunks, graph_model)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mextract_graph_from_data\u001B[39m(\n\u001B[1;32m     17\u001B[0m     data_chunks: \u001B[38;5;28mlist\u001B[39m[DocumentChunk], graph_model: Type[BaseModel]\n\u001B[1;32m     18\u001B[0m ):\n\u001B[0;32m---> 19\u001B[0m     chunk_graphs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39mgather(\n\u001B[1;32m     20\u001B[0m         \u001B[38;5;241m*\u001B[39m[extract_content_graph(chunk\u001B[38;5;241m.\u001B[39mtext, graph_model) \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m data_chunks]\n\u001B[1;32m     21\u001B[0m     )\n\u001B[1;32m     22\u001B[0m     graph_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m get_graph_engine()\n\u001B[1;32m     24\u001B[0m     existing_edges_map \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m retrieve_existing_edges(\n\u001B[1;32m     25\u001B[0m         data_chunks,\n\u001B[1;32m     26\u001B[0m         chunk_graphs,\n\u001B[1;32m     27\u001B[0m         graph_engine,\n\u001B[1;32m     28\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/modules/data/extraction/knowledge_graph/extract_content_graph.py:10\u001B[0m, in \u001B[0;36mextract_content_graph\u001B[0;34m(content, response_model)\u001B[0m\n\u001B[1;32m      7\u001B[0m llm_client \u001B[38;5;241m=\u001B[39m get_llm_client()\n\u001B[1;32m      9\u001B[0m system_prompt \u001B[38;5;241m=\u001B[39m render_prompt(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerate_graph_prompt.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\n\u001B[0;32m---> 10\u001B[0m content_graph \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m llm_client\u001B[38;5;241m.\u001B[39macreate_structured_output(content, system_prompt, response_model)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m content_graph\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/cognee/infrastructure/llm/openai/adapter.py:42\u001B[0m, in \u001B[0;36mOpenAIAdapter.acreate_structured_output\u001B[0;34m(self, text_input, system_prompt, response_model)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21macreate_structured_output\u001B[39m(\u001B[38;5;28mself\u001B[39m, text_input: \u001B[38;5;28mstr\u001B[39m, system_prompt: \u001B[38;5;28mstr\u001B[39m, response_model: Type[BaseModel]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseModel:\n\u001B[1;32m     40\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Generate a response from a user query.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maclient\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m     43\u001B[0m         model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel,\n\u001B[1;32m     44\u001B[0m         messages \u001B[38;5;241m=\u001B[39m [{\n\u001B[1;32m     45\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     46\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mUse the given format to\u001B[39m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;124m            extract information from the following input: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext_input\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m,\n\u001B[1;32m     48\u001B[0m         }, {\n\u001B[1;32m     49\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     50\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: system_prompt,\n\u001B[1;32m     51\u001B[0m         }],\n\u001B[1;32m     52\u001B[0m         api_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key,\n\u001B[1;32m     53\u001B[0m         api_base \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mendpoint,\n\u001B[1;32m     54\u001B[0m         api_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_version,\n\u001B[1;32m     55\u001B[0m         response_model \u001B[38;5;241m=\u001B[39m response_model,\n\u001B[1;32m     56\u001B[0m         max_retries \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m,\n\u001B[1;32m     57\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/client.py:311\u001B[0m, in \u001B[0;36mAsyncInstructor.create\u001B[0;34m(self, response_model, messages, max_retries, validation_context, context, strict, **kwargs)\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    302\u001B[0m     response_model: \u001B[38;5;28mtype\u001B[39m[T] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    309\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T \u001B[38;5;241m|\u001B[39m Any:\n\u001B[1;32m    310\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_kwargs(kwargs)\n\u001B[0;32m--> 311\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_fn(\n\u001B[1;32m    312\u001B[0m         response_model\u001B[38;5;241m=\u001B[39mresponse_model,\n\u001B[1;32m    313\u001B[0m         validation_context\u001B[38;5;241m=\u001B[39mvalidation_context,\n\u001B[1;32m    314\u001B[0m         context\u001B[38;5;241m=\u001B[39mcontext,\n\u001B[1;32m    315\u001B[0m         max_retries\u001B[38;5;241m=\u001B[39mmax_retries,\n\u001B[1;32m    316\u001B[0m         messages\u001B[38;5;241m=\u001B[39mmessages,\n\u001B[1;32m    317\u001B[0m         strict\u001B[38;5;241m=\u001B[39mstrict,\n\u001B[1;32m    318\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    319\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/patch.py:255\u001B[0m, in \u001B[0;36mpatch.<locals>.new_create_async\u001B[0;34m(response_model, validation_context, context, max_retries, strict, *args, **kwargs)\u001B[0m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontents\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m new_kwargs:\n\u001B[1;32m    252\u001B[0m     new_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontents\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m handle_templating(new_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontents\u001B[39m\u001B[38;5;124m\"\u001B[39m], context)\n\u001B[0;32m--> 255\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m retry_async(\n\u001B[1;32m    256\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    257\u001B[0m     response_model\u001B[38;5;241m=\u001B[39mresponse_model,\n\u001B[1;32m    258\u001B[0m     context\u001B[38;5;241m=\u001B[39mcontext,\n\u001B[1;32m    259\u001B[0m     max_retries\u001B[38;5;241m=\u001B[39mmax_retries,\n\u001B[1;32m    260\u001B[0m     args\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m    261\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mnew_kwargs,\n\u001B[1;32m    262\u001B[0m     strict\u001B[38;5;241m=\u001B[39mstrict,\n\u001B[1;32m    263\u001B[0m     mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[1;32m    264\u001B[0m )\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/Documents/Advance_RAG/.venv/lib/python3.9/site-packages/instructor/retry.py:306\u001B[0m, in \u001B[0;36mretry_async\u001B[0;34m(func, response_model, context, args, kwargs, max_retries, strict, mode)\u001B[0m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RetryError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    305\u001B[0m     logger\u001B[38;5;241m.\u001B[39mexception(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed after retries: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;241m.\u001B[39mlast_attempt\u001B[38;5;241m.\u001B[39mexception\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 306\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m InstructorRetryException(\n\u001B[1;32m    307\u001B[0m         e\u001B[38;5;241m.\u001B[39mlast_attempt\u001B[38;5;241m.\u001B[39m_exception,\n\u001B[1;32m    308\u001B[0m         last_completion\u001B[38;5;241m=\u001B[39mresponse,\n\u001B[1;32m    309\u001B[0m         n_attempts\u001B[38;5;241m=\u001B[39mattempt\u001B[38;5;241m.\u001B[39mretry_state\u001B[38;5;241m.\u001B[39mattempt_number,\n\u001B[1;32m    310\u001B[0m         messages\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m    311\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontents\u001B[39m\u001B[38;5;124m\"\u001B[39m, kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchat_history\u001B[39m\u001B[38;5;124m\"\u001B[39m, []))\n\u001B[1;32m    312\u001B[0m         ),\n\u001B[1;32m    313\u001B[0m         total_usage\u001B[38;5;241m=\u001B[39mtotal_usage,\n\u001B[1;32m    314\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mInstructorRetryException\u001B[0m: litellm.APIError: APIError: OpenAIException - __init__() got an unexpected keyword argument 'proxies'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "78915876fdbf88b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
