import os
from dotenv import load_dotenv
from openai import OpenAI
from typing import List
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor

# Load environment variables from a .env file.
load_dotenv()

# Retrieve the API key from the environment.
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY environment variable is not set.")

# Initialize the OpenAI client with the API key.
client = OpenAI(api_key=api_key)


def get_embedding(text: str, model: str = "text-embedding-3-small") -> List[float]:
    """
    Generate an embedding for the given text using the specified OpenAI model.

    The function first cleans the input text by replacing newline characters with spaces,
    then calls the OpenAI API to generate the embedding.

    Args:
        text (str): The input text for which to generate an embedding.
        model (str): The identifier for the embedding model. Defaults to "text-embedding-3-small".

    Returns:
        List[float]: The embedding vector generated by the model.

    Raises:
        Exception: If the API call fails or an error occurs during the request.
    """
    # Clean the input text by replacing newline characters with spaces.
    cleaned_text = text.replace("\n", " ")

    try:
        # Request the embedding from the OpenAI API.
        response = client.embeddings.create(input=[cleaned_text], model=model)
        # Extract the embedding vector from the response data.
        embedding = response.data[0].embedding
    except Exception as e:
        # Raise an exception with additional context if the API call fails.
        raise Exception(f"Error generating embedding: {e}")

    return embedding


from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm


def compute_embedding(item):
    """
    Compute the embedding for a single data item.

    Args:
        item (dict): A dictionary containing at least 'id' and 'content'.

    Returns:
        dict: A dictionary containing the id, computed embedding, and the original metadata.
    """
    return {
        "id": str(item["id"]),
        "values": get_embedding(item["content"], model="text-embedding-3-large"),
        "metadata": item
    }


def get_dataset_embeddings_parallel(data):
    """
    Compute embeddings for all data items in parallel using threads.

    Args:
        data (list): A list of dictionaries, each with keys 'id' and 'content'.

    Returns:
        list: A list of dictionaries with embeddings and metadata.
    """
    with ThreadPoolExecutor() as executor:
        # Use executor.map to apply compute_embedding to each item in data.
        results = list(tqdm(executor.map(compute_embedding, data), total=len(data)))
    return results
