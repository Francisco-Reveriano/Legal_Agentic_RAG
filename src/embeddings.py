import os
from openai import OpenAI
from typing import List
from dotenv import load_dotenv
import warnings
warnings.filterwarnings("ignore")
load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
pinecone_api_key = os.getenv("PINECONE_API_KEY")
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm



def get_embedding(text: str, model: str = "text-embedding-3-large") -> List[float]:
    """
    Generate an embedding for the given text using the specified OpenAI model.

    The function first cleans the input text by replacing newline characters with spaces,
    then calls the OpenAI API to generate the embedding.

    Args:
        text (str): The input text for which to generate an embedding.
        model (str): The identifier for the embedding model. Defaults to "text-embedding-3-small".

    Returns:
        List[float]: The embedding vector generated by the model.

    Raises:
        Exception: If the API call fails or an error occurs during the request.
    """
    # Clean the input text by replacing newline characters with spaces.
    #cleaned_text = text.replace("\n", "")

    # Create Client
    # Initialize the OpenAI client with the API key.
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    try:
        # Request the embedding from the OpenAI API.
        response = client.embeddings.create(input=text, model=model)
        # Extract the embedding vector from the response data.
        embedding = response.data[0].embedding
    except Exception as e:
        # Raise an exception with additional context if the API call fails.
        raise Exception(f"Error generating embedding: {e}")

    return embedding


def compute_embedding(item):

    return {
        "id": str(item["id"]),
        "values": get_embedding(item["content"]),
        "metadata": item
    }


def get_dataset_embeddings_parallel(data):

    with ThreadPoolExecutor() as executor:
        # Use executor.map to apply compute_embedding to each item in data.
        results = list(tqdm(executor.map(compute_embedding, data), total=len(data)))
    return results
